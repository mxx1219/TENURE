# config.yaml

seed: 2
save_data: check_point/copy_single/
overwrite: true
## Where the vocab(s) will be written
src_vocab: vocab/copy_single.vocab
share_vocab: true
#n_sample: -1

# Corpus opts:
data:
    train:
        path_src: ../dataset/dataset_sl/train/src.txt
        path_tgt: ../dataset/dataset_sl/train/tgt.txt
    valid:
        path_src: ../dataset/dataset_sl/val/src.txt
        path_tgt: ../dataset/dataset_sl/val/tgt.txt

# Training
## GPU settings
world_size: 1
gpu_ranks: [0]

# Vocab settings
src_vocab_size: 30000

# Where to save the checkpoints
save_model: check_point/copy_single/model
save_checkpoint_steps: 10000
train_steps: 200000
valid_steps: 10000

## Batching
batch_size: 32
valid_batch_size: 32

## Optimizer
optim: "adam"
learning_rate: 0.001

## Attention 
copy_attn: true
reuse_copy_attn: true

## Model
encoder_type: brnn
decoder_type: rnn
enc_layers: 2
dec_layers: 2
rnn_size: 128
word_vec_size: 128
